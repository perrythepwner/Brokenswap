{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.deserializeTreeOffsetProof = exports.serializeTreeOffsetProof = exports.computeTreeOffsetProofSerializedLength = exports.createNodeFromTreeOffsetProof = exports.createTreeOffsetProof = exports.treeOffsetProofToNode = exports.nodeToTreeOffsetProof = void 0;\nconst node_1 = require(\"../node\");\nconst util_1 = require(\"./util\");\n/**\n * Compute offsets and leaves of a tree-offset proof\n *\n * Recursive function\n *\n * See https://github.com/protolambda/eth-merkle-trees/blob/master/tree_offsets.md\n * @param node current node in the tree\n * @param gindex current generalized index in the tree\n * @param proofGindices generalized indices to left include in the proof - must be sorted in-order according to the tree\n */\nfunction nodeToTreeOffsetProof(node, gindex, proofGindices) {\n  if (!proofGindices.length || !proofGindices[0].startsWith(gindex)) {\n    // there are no proof indices left OR the current subtree contains no remaining proof indices\n    return [[], []];\n  } else if (gindex === proofGindices[0]) {\n    // the current node is at the next proof index\n    proofGindices.shift();\n    return [[], [node.root]];\n  } else {\n    // recursively compute offsets, leaves for the left and right subtree\n    const [leftOffsets, leftLeaves] = nodeToTreeOffsetProof(node.left, gindex + \"0\", proofGindices);\n    const [rightOffsets, rightLeaves] = nodeToTreeOffsetProof(node.right, gindex + \"1\", proofGindices);\n    // the offset prepended to the list is # of leaves in the left subtree\n    const pivot = leftLeaves.length;\n    return [[pivot].concat(leftOffsets, rightOffsets), leftLeaves.concat(rightLeaves)];\n  }\n}\nexports.nodeToTreeOffsetProof = nodeToTreeOffsetProof;\n/**\n * Recreate a `Node` given offsets and leaves of a tree-offset proof\n *\n * Recursive definition\n *\n * See https://github.com/protolambda/eth-merkle-trees/blob/master/tree_offsets.md\n */\nfunction treeOffsetProofToNode(offsets, leaves) {\n  if (!leaves.length) {\n    throw new Error(\"Proof must contain gt 0 leaves\");\n  } else if (leaves.length === 1) {\n    return node_1.LeafNode.fromRoot(leaves[0]);\n  } else {\n    // the offset popped from the list is the # of leaves in the left subtree\n    const pivot = offsets[0];\n    return new node_1.BranchNode(treeOffsetProofToNode(offsets.slice(1, pivot), leaves.slice(0, pivot)), treeOffsetProofToNode(offsets.slice(pivot), leaves.slice(pivot)));\n  }\n}\nexports.treeOffsetProofToNode = treeOffsetProofToNode;\n/**\n * Create a tree-offset proof\n *\n * @param rootNode the root node of the tree\n * @param gindices generalized indices to include in the proof\n */\nfunction createTreeOffsetProof(rootNode, gindices) {\n  return nodeToTreeOffsetProof(rootNode, \"1\", util_1.computeMultiProofBitstrings(gindices.map(g => g.toString(2))));\n}\nexports.createTreeOffsetProof = createTreeOffsetProof;\n/**\n * Recreate a `Node` given a tree-offset proof\n *\n * @param offsets offsets of a tree-offset proof\n * @param leaves leaves of a tree-offset proof\n */\nfunction createNodeFromTreeOffsetProof(offsets, leaves) {\n  // TODO validation\n  return treeOffsetProofToNode(offsets, leaves);\n}\nexports.createNodeFromTreeOffsetProof = createNodeFromTreeOffsetProof;\nfunction computeTreeOffsetProofSerializedLength(offsets, leaves) {\n  // add 1 for # of leaves\n  return (offsets.length + 1) * 2 + leaves.length * 32;\n}\nexports.computeTreeOffsetProofSerializedLength = computeTreeOffsetProofSerializedLength;\n// Serialized tree offset proof structure:\n// # of leaves - 2 bytes\n// offsets - 2 bytes each\n// leaves - 32 bytes each\nfunction serializeTreeOffsetProof(output, byteOffset, offsets, leaves) {\n  const writer = new DataView(output.buffer, output.byteOffset, output.byteLength);\n  // set # of leaves\n  writer.setUint16(byteOffset, leaves.length, true);\n  // set offsets\n  const offsetsStartIndex = byteOffset + 2;\n  for (let i = 0; i < offsets.length; i++) {\n    writer.setUint16(i * 2 + offsetsStartIndex, offsets[i], true);\n  }\n  // set leaves\n  const leavesStartIndex = offsetsStartIndex + offsets.length * 2;\n  for (let i = 0; i < leaves.length; i++) {\n    output.set(leaves[i], i * 32 + leavesStartIndex);\n  }\n}\nexports.serializeTreeOffsetProof = serializeTreeOffsetProof;\nfunction deserializeTreeOffsetProof(data, byteOffset) {\n  const reader = new DataView(data.buffer, data.byteOffset, data.byteLength);\n  // get # of leaves\n  const leafCount = reader.getUint16(byteOffset, true);\n  if (data.length < (leafCount - 1) * 2 + leafCount * 32) {\n    throw new Error(\"Unable to deserialize tree offset proof: not enough bytes\");\n  }\n  // get offsets\n  const offsetsStartIndex = byteOffset + 2;\n  const offsets = Array.from({\n    length: leafCount - 1\n  }, (_, i) => reader.getUint16(i * 2 + offsetsStartIndex, true));\n  // get leaves\n  const leavesStartIndex = offsetsStartIndex + offsets.length * 2;\n  const leaves = Array.from({\n    length: leafCount\n  }, (_, i) => data.subarray(i * 32 + leavesStartIndex, (i + 1) * 32 + leavesStartIndex));\n  return [offsets, leaves];\n}\nexports.deserializeTreeOffsetProof = deserializeTreeOffsetProof;","map":{"version":3,"names":["Object","defineProperty","exports","value","deserializeTreeOffsetProof","serializeTreeOffsetProof","computeTreeOffsetProofSerializedLength","createNodeFromTreeOffsetProof","createTreeOffsetProof","treeOffsetProofToNode","nodeToTreeOffsetProof","node_1","require","util_1","node","gindex","proofGindices","length","startsWith","shift","root","leftOffsets","leftLeaves","left","rightOffsets","rightLeaves","right","pivot","concat","offsets","leaves","Error","LeafNode","fromRoot","BranchNode","slice","rootNode","gindices","computeMultiProofBitstrings","map","g","toString","output","byteOffset","writer","DataView","buffer","byteLength","setUint16","offsetsStartIndex","i","leavesStartIndex","set","data","reader","leafCount","getUint16","Array","from","_","subarray"],"sources":["/home/simone/Scrivania/progetti/HTB_challs/HackTheBoo_23/VeryEasy2/Brokenswap/frontend/node_modules/@chainsafe/persistent-merkle-tree/lib/proof/treeOffset.js"],"sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.deserializeTreeOffsetProof = exports.serializeTreeOffsetProof = exports.computeTreeOffsetProofSerializedLength = exports.createNodeFromTreeOffsetProof = exports.createTreeOffsetProof = exports.treeOffsetProofToNode = exports.nodeToTreeOffsetProof = void 0;\nconst node_1 = require(\"../node\");\nconst util_1 = require(\"./util\");\n/**\n * Compute offsets and leaves of a tree-offset proof\n *\n * Recursive function\n *\n * See https://github.com/protolambda/eth-merkle-trees/blob/master/tree_offsets.md\n * @param node current node in the tree\n * @param gindex current generalized index in the tree\n * @param proofGindices generalized indices to left include in the proof - must be sorted in-order according to the tree\n */\nfunction nodeToTreeOffsetProof(node, gindex, proofGindices) {\n    if (!proofGindices.length || !proofGindices[0].startsWith(gindex)) {\n        // there are no proof indices left OR the current subtree contains no remaining proof indices\n        return [[], []];\n    }\n    else if (gindex === proofGindices[0]) {\n        // the current node is at the next proof index\n        proofGindices.shift();\n        return [[], [node.root]];\n    }\n    else {\n        // recursively compute offsets, leaves for the left and right subtree\n        const [leftOffsets, leftLeaves] = nodeToTreeOffsetProof(node.left, gindex + \"0\", proofGindices);\n        const [rightOffsets, rightLeaves] = nodeToTreeOffsetProof(node.right, gindex + \"1\", proofGindices);\n        // the offset prepended to the list is # of leaves in the left subtree\n        const pivot = leftLeaves.length;\n        return [[pivot].concat(leftOffsets, rightOffsets), leftLeaves.concat(rightLeaves)];\n    }\n}\nexports.nodeToTreeOffsetProof = nodeToTreeOffsetProof;\n/**\n * Recreate a `Node` given offsets and leaves of a tree-offset proof\n *\n * Recursive definition\n *\n * See https://github.com/protolambda/eth-merkle-trees/blob/master/tree_offsets.md\n */\nfunction treeOffsetProofToNode(offsets, leaves) {\n    if (!leaves.length) {\n        throw new Error(\"Proof must contain gt 0 leaves\");\n    }\n    else if (leaves.length === 1) {\n        return node_1.LeafNode.fromRoot(leaves[0]);\n    }\n    else {\n        // the offset popped from the list is the # of leaves in the left subtree\n        const pivot = offsets[0];\n        return new node_1.BranchNode(treeOffsetProofToNode(offsets.slice(1, pivot), leaves.slice(0, pivot)), treeOffsetProofToNode(offsets.slice(pivot), leaves.slice(pivot)));\n    }\n}\nexports.treeOffsetProofToNode = treeOffsetProofToNode;\n/**\n * Create a tree-offset proof\n *\n * @param rootNode the root node of the tree\n * @param gindices generalized indices to include in the proof\n */\nfunction createTreeOffsetProof(rootNode, gindices) {\n    return nodeToTreeOffsetProof(rootNode, \"1\", util_1.computeMultiProofBitstrings(gindices.map((g) => g.toString(2))));\n}\nexports.createTreeOffsetProof = createTreeOffsetProof;\n/**\n * Recreate a `Node` given a tree-offset proof\n *\n * @param offsets offsets of a tree-offset proof\n * @param leaves leaves of a tree-offset proof\n */\nfunction createNodeFromTreeOffsetProof(offsets, leaves) {\n    // TODO validation\n    return treeOffsetProofToNode(offsets, leaves);\n}\nexports.createNodeFromTreeOffsetProof = createNodeFromTreeOffsetProof;\nfunction computeTreeOffsetProofSerializedLength(offsets, leaves) {\n    // add 1 for # of leaves\n    return (offsets.length + 1) * 2 + leaves.length * 32;\n}\nexports.computeTreeOffsetProofSerializedLength = computeTreeOffsetProofSerializedLength;\n// Serialized tree offset proof structure:\n// # of leaves - 2 bytes\n// offsets - 2 bytes each\n// leaves - 32 bytes each\nfunction serializeTreeOffsetProof(output, byteOffset, offsets, leaves) {\n    const writer = new DataView(output.buffer, output.byteOffset, output.byteLength);\n    // set # of leaves\n    writer.setUint16(byteOffset, leaves.length, true);\n    // set offsets\n    const offsetsStartIndex = byteOffset + 2;\n    for (let i = 0; i < offsets.length; i++) {\n        writer.setUint16(i * 2 + offsetsStartIndex, offsets[i], true);\n    }\n    // set leaves\n    const leavesStartIndex = offsetsStartIndex + offsets.length * 2;\n    for (let i = 0; i < leaves.length; i++) {\n        output.set(leaves[i], i * 32 + leavesStartIndex);\n    }\n}\nexports.serializeTreeOffsetProof = serializeTreeOffsetProof;\nfunction deserializeTreeOffsetProof(data, byteOffset) {\n    const reader = new DataView(data.buffer, data.byteOffset, data.byteLength);\n    // get # of leaves\n    const leafCount = reader.getUint16(byteOffset, true);\n    if (data.length < (leafCount - 1) * 2 + leafCount * 32) {\n        throw new Error(\"Unable to deserialize tree offset proof: not enough bytes\");\n    }\n    // get offsets\n    const offsetsStartIndex = byteOffset + 2;\n    const offsets = Array.from({ length: leafCount - 1 }, (_, i) => reader.getUint16(i * 2 + offsetsStartIndex, true));\n    // get leaves\n    const leavesStartIndex = offsetsStartIndex + offsets.length * 2;\n    const leaves = Array.from({ length: leafCount }, (_, i) => data.subarray(i * 32 + leavesStartIndex, (i + 1) * 32 + leavesStartIndex));\n    return [offsets, leaves];\n}\nexports.deserializeTreeOffsetProof = deserializeTreeOffsetProof;\n"],"mappings":"AAAA,YAAY;;AACZA,MAAM,CAACC,cAAc,CAACC,OAAO,EAAE,YAAY,EAAE;EAAEC,KAAK,EAAE;AAAK,CAAC,CAAC;AAC7DD,OAAO,CAACE,0BAA0B,GAAGF,OAAO,CAACG,wBAAwB,GAAGH,OAAO,CAACI,sCAAsC,GAAGJ,OAAO,CAACK,6BAA6B,GAAGL,OAAO,CAACM,qBAAqB,GAAGN,OAAO,CAACO,qBAAqB,GAAGP,OAAO,CAACQ,qBAAqB,GAAG,KAAK,CAAC;AACvQ,MAAMC,MAAM,GAAGC,OAAO,CAAC,SAAS,CAAC;AACjC,MAAMC,MAAM,GAAGD,OAAO,CAAC,QAAQ,CAAC;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASF,qBAAqBA,CAACI,IAAI,EAAEC,MAAM,EAAEC,aAAa,EAAE;EACxD,IAAI,CAACA,aAAa,CAACC,MAAM,IAAI,CAACD,aAAa,CAAC,CAAC,CAAC,CAACE,UAAU,CAACH,MAAM,CAAC,EAAE;IAC/D;IACA,OAAO,CAAC,EAAE,EAAE,EAAE,CAAC;EACnB,CAAC,MACI,IAAIA,MAAM,KAAKC,aAAa,CAAC,CAAC,CAAC,EAAE;IAClC;IACAA,aAAa,CAACG,KAAK,CAAC,CAAC;IACrB,OAAO,CAAC,EAAE,EAAE,CAACL,IAAI,CAACM,IAAI,CAAC,CAAC;EAC5B,CAAC,MACI;IACD;IACA,MAAM,CAACC,WAAW,EAAEC,UAAU,CAAC,GAAGZ,qBAAqB,CAACI,IAAI,CAACS,IAAI,EAAER,MAAM,GAAG,GAAG,EAAEC,aAAa,CAAC;IAC/F,MAAM,CAACQ,YAAY,EAAEC,WAAW,CAAC,GAAGf,qBAAqB,CAACI,IAAI,CAACY,KAAK,EAAEX,MAAM,GAAG,GAAG,EAAEC,aAAa,CAAC;IAClG;IACA,MAAMW,KAAK,GAAGL,UAAU,CAACL,MAAM;IAC/B,OAAO,CAAC,CAACU,KAAK,CAAC,CAACC,MAAM,CAACP,WAAW,EAAEG,YAAY,CAAC,EAAEF,UAAU,CAACM,MAAM,CAACH,WAAW,CAAC,CAAC;EACtF;AACJ;AACAvB,OAAO,CAACQ,qBAAqB,GAAGA,qBAAqB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASD,qBAAqBA,CAACoB,OAAO,EAAEC,MAAM,EAAE;EAC5C,IAAI,CAACA,MAAM,CAACb,MAAM,EAAE;IAChB,MAAM,IAAIc,KAAK,CAAC,gCAAgC,CAAC;EACrD,CAAC,MACI,IAAID,MAAM,CAACb,MAAM,KAAK,CAAC,EAAE;IAC1B,OAAON,MAAM,CAACqB,QAAQ,CAACC,QAAQ,CAACH,MAAM,CAAC,CAAC,CAAC,CAAC;EAC9C,CAAC,MACI;IACD;IACA,MAAMH,KAAK,GAAGE,OAAO,CAAC,CAAC,CAAC;IACxB,OAAO,IAAIlB,MAAM,CAACuB,UAAU,CAACzB,qBAAqB,CAACoB,OAAO,CAACM,KAAK,CAAC,CAAC,EAAER,KAAK,CAAC,EAAEG,MAAM,CAACK,KAAK,CAAC,CAAC,EAAER,KAAK,CAAC,CAAC,EAAElB,qBAAqB,CAACoB,OAAO,CAACM,KAAK,CAACR,KAAK,CAAC,EAAEG,MAAM,CAACK,KAAK,CAACR,KAAK,CAAC,CAAC,CAAC;EAC1K;AACJ;AACAzB,OAAO,CAACO,qBAAqB,GAAGA,qBAAqB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA,SAASD,qBAAqBA,CAAC4B,QAAQ,EAAEC,QAAQ,EAAE;EAC/C,OAAO3B,qBAAqB,CAAC0B,QAAQ,EAAE,GAAG,EAAEvB,MAAM,CAACyB,2BAA2B,CAACD,QAAQ,CAACE,GAAG,CAAEC,CAAC,IAAKA,CAAC,CAACC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;AACvH;AACAvC,OAAO,CAACM,qBAAqB,GAAGA,qBAAqB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA,SAASD,6BAA6BA,CAACsB,OAAO,EAAEC,MAAM,EAAE;EACpD;EACA,OAAOrB,qBAAqB,CAACoB,OAAO,EAAEC,MAAM,CAAC;AACjD;AACA5B,OAAO,CAACK,6BAA6B,GAAGA,6BAA6B;AACrE,SAASD,sCAAsCA,CAACuB,OAAO,EAAEC,MAAM,EAAE;EAC7D;EACA,OAAO,CAACD,OAAO,CAACZ,MAAM,GAAG,CAAC,IAAI,CAAC,GAAGa,MAAM,CAACb,MAAM,GAAG,EAAE;AACxD;AACAf,OAAO,CAACI,sCAAsC,GAAGA,sCAAsC;AACvF;AACA;AACA;AACA;AACA,SAASD,wBAAwBA,CAACqC,MAAM,EAAEC,UAAU,EAAEd,OAAO,EAAEC,MAAM,EAAE;EACnE,MAAMc,MAAM,GAAG,IAAIC,QAAQ,CAACH,MAAM,CAACI,MAAM,EAAEJ,MAAM,CAACC,UAAU,EAAED,MAAM,CAACK,UAAU,CAAC;EAChF;EACAH,MAAM,CAACI,SAAS,CAACL,UAAU,EAAEb,MAAM,CAACb,MAAM,EAAE,IAAI,CAAC;EACjD;EACA,MAAMgC,iBAAiB,GAAGN,UAAU,GAAG,CAAC;EACxC,KAAK,IAAIO,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGrB,OAAO,CAACZ,MAAM,EAAEiC,CAAC,EAAE,EAAE;IACrCN,MAAM,CAACI,SAAS,CAACE,CAAC,GAAG,CAAC,GAAGD,iBAAiB,EAAEpB,OAAO,CAACqB,CAAC,CAAC,EAAE,IAAI,CAAC;EACjE;EACA;EACA,MAAMC,gBAAgB,GAAGF,iBAAiB,GAAGpB,OAAO,CAACZ,MAAM,GAAG,CAAC;EAC/D,KAAK,IAAIiC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGpB,MAAM,CAACb,MAAM,EAAEiC,CAAC,EAAE,EAAE;IACpCR,MAAM,CAACU,GAAG,CAACtB,MAAM,CAACoB,CAAC,CAAC,EAAEA,CAAC,GAAG,EAAE,GAAGC,gBAAgB,CAAC;EACpD;AACJ;AACAjD,OAAO,CAACG,wBAAwB,GAAGA,wBAAwB;AAC3D,SAASD,0BAA0BA,CAACiD,IAAI,EAAEV,UAAU,EAAE;EAClD,MAAMW,MAAM,GAAG,IAAIT,QAAQ,CAACQ,IAAI,CAACP,MAAM,EAAEO,IAAI,CAACV,UAAU,EAAEU,IAAI,CAACN,UAAU,CAAC;EAC1E;EACA,MAAMQ,SAAS,GAAGD,MAAM,CAACE,SAAS,CAACb,UAAU,EAAE,IAAI,CAAC;EACpD,IAAIU,IAAI,CAACpC,MAAM,GAAG,CAACsC,SAAS,GAAG,CAAC,IAAI,CAAC,GAAGA,SAAS,GAAG,EAAE,EAAE;IACpD,MAAM,IAAIxB,KAAK,CAAC,2DAA2D,CAAC;EAChF;EACA;EACA,MAAMkB,iBAAiB,GAAGN,UAAU,GAAG,CAAC;EACxC,MAAMd,OAAO,GAAG4B,KAAK,CAACC,IAAI,CAAC;IAAEzC,MAAM,EAAEsC,SAAS,GAAG;EAAE,CAAC,EAAE,CAACI,CAAC,EAAET,CAAC,KAAKI,MAAM,CAACE,SAAS,CAACN,CAAC,GAAG,CAAC,GAAGD,iBAAiB,EAAE,IAAI,CAAC,CAAC;EAClH;EACA,MAAME,gBAAgB,GAAGF,iBAAiB,GAAGpB,OAAO,CAACZ,MAAM,GAAG,CAAC;EAC/D,MAAMa,MAAM,GAAG2B,KAAK,CAACC,IAAI,CAAC;IAAEzC,MAAM,EAAEsC;EAAU,CAAC,EAAE,CAACI,CAAC,EAAET,CAAC,KAAKG,IAAI,CAACO,QAAQ,CAACV,CAAC,GAAG,EAAE,GAAGC,gBAAgB,EAAE,CAACD,CAAC,GAAG,CAAC,IAAI,EAAE,GAAGC,gBAAgB,CAAC,CAAC;EACrI,OAAO,CAACtB,OAAO,EAAEC,MAAM,CAAC;AAC5B;AACA5B,OAAO,CAACE,0BAA0B,GAAGA,0BAA0B"},"metadata":{},"sourceType":"script"}